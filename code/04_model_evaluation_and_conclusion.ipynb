{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a41d35",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f50d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for webscraping\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import regex as re\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd28bbb",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde6885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9539283",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4da573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adopted from class\n",
    "def c_matrix(model, X_test):\n",
    "    model.fit(X_train, y_train) \n",
    "    y_pred = model.predict(X_test)            # calculate predictions\n",
    "    cm = confusion_matrix(y_test, y_pred)    # defining the confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()               # assigning the elements of the confusion matrix to variables\n",
    "    \n",
    "    spec = tn / (tn + fp)                     # calculate the specificity\n",
    "    sens = tp / (tp + fn)                     # calculate the sensitivity\n",
    "    \n",
    "    print('Specificity:', spec)\n",
    "    print('Sensitivity:', sens)\n",
    "    \n",
    "    # View confusion matrix\n",
    "    #ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='Blues', values_format='d')\n",
    "\n",
    "    return pd.DataFrame(cm, \n",
    "                        columns = ['Predict AwardTravel','Predict TravelHack'], \n",
    "                        index = ['Actual AwardTravel', 'Actual TravelHack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18601c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_matrix(model, X_test, y_test):\n",
    "    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3042078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer and LogisticRegression\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pipe_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCountVectorizer and LogisticRegression\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m c_matrix(\u001b[43mpipe_log\u001b[49m, X_test)\n\u001b[0;32m      4\u001b[0m display_matrix(pipe_log, X_test, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe_log' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"CountVectorizer and LogisticRegression\")\n",
    "c_matrix(pipe_log, X_test)\n",
    "\n",
    "display_matrix(pipe_log, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8362ad8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Grid Search of CountVectorizer and LogisticRegression\")\n",
    "c_matrix(gs, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_matrix(gs, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cde25c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"CountVectorizer and MultinomialNB\")\n",
    "c_matrix(pipe_nb, X_test)\n",
    "\n",
    "display_matrix(pipe_nb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca029ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search of CountVectorizer and MultinomialNB\")\n",
    "c_matrix(gs_2, X_test)\n",
    "display_matrix(gs_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcff4d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"TfidfVectorizer and LogisticRegression\")\n",
    "c_matrix(pipe_tvec_log, X_test)\n",
    "display_matrix(pipe_tvec_log, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search of TfidfVectorizer and LogisticRegression\")\n",
    "c_matrix(gs_3, X_test)\n",
    "display_matrix(gs_3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"TfidfVectorizer and MultinomialNB\")\n",
    "c_matrix(pipe_tvec_nb, X_test)\n",
    "display_matrix(pipe_tvec_nb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6747bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search of TfidfVectorizer and MultinomialNB\")\n",
    "c_matrix(gs_4, X_test)\n",
    "display_matrix(gs_4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afdabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 4))\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(gs_rf, X_test, y_test, ax=ax1, cmap='Blues', values_format='d')\n",
    "ax1.xaxis.set_ticklabels(['auto', 'tft']); ax1.yaxis.set_ticklabels(['auto', 'tft'])\n",
    "ax1.set_title('RandomForest - GridSearchCV Confusion Matrix')\n",
    "\n",
    "plot_confusion_matrix(best_nb, X_test, y_test, ax=ax2, cmap='Blues', values_format='d')\n",
    "ax2.xaxis.set_ticklabels(['auto', 'tft']); ax2.yaxis.set_ticklabels(['auto', 'tft'])\n",
    "ax2.set_title('NaiveBayes - Confusion Matrix')\n",
    "\n",
    "plot_confusion_matrix(best_logr, X_test, y_test, ax=ax3, cmap='Blues', values_format='d')\n",
    "ax3.xaxis.set_ticklabels(['auto', 'tft']); ax3.yaxis.set_ticklabels(['auto', 'tft'])\n",
    "ax3.set_title('Logistic Regression - Confusion Matrix');\n",
    "\n",
    "# plt.savefig(\"./images/confusion_matrix_evaluation.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b4207",
   "metadata": {},
   "source": [
    "#### Make a function to show scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a091b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from class\n",
    "def matrix_score(classifier, X, y):\n",
    "    \"\"\"fit and score a model - print and return accuracy and predict_proba\n",
    "    \n",
    "    Args:\n",
    "        classifier: an instance of a scikit-learn classification estimator\n",
    "        X (2d pd.DataFrame or np.ndarray): features \n",
    "        y (1d pd.Series on np.ndarry): outcome variable\n",
    "    \n",
    "    Returns: \n",
    "        accuracy score (float): accuracy on the X_test\n",
    "        predict_proba (array of floats): predicted probabilities for each class for each sample\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    proba = np.round(classifier.predict_proba(X_test),2)\n",
    "    return f\"score: {score}\\nproba: {proba}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a56e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4f9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2eb1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
